\section*{Introduction}

This report explains the implementation details of CS523 Computer Vision
Assignment 2, which is about training a kNN classifier on the MNIST dataset,
reducing the dimensions with Principal Component Analysis(PCA) and using the
classifier on the Sudoku Dataset to recognize the digits. I will explain the
idea behind PCA for reducing the dimensions, the kNN classifier, processing
methods I have used to extract digits from the Sudoku Dataset and lastly comment
on my results.

To run the code, there needs to be an images directory where the .dat files and
.jpg files are located. Also
\href{https://pypi.org/project/python-mnist/} {python-mnist} needs to be
installed to load the MNIST dataset into numpy arrays.


\section*{About Principal Component Analysis} Principal Component Analysis(PCA)
is an algorithm used for dimensionality reduction. In the MNIST hand written
digits dataset, each image comes as vectors of dimension 784. However, we do
not need all the dimensions contain classifying an image.  The idea is,
compressing a matrix with a lot of features into a smaller matrix, with less
features which preserves as much of the information in the full matrix as
possible.

In my PCA algorithm, I first did stuff.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/before-after-pca.png}
    \caption*{PCA results}
    \setlength{\belowcaptionskip}{-20pt}
    \setlength{\abovecaptionskip}{-20pt}
\end{figure}


\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/pca.png}
    \caption*{PCA results}
    \setlength{\belowcaptionskip}{-20pt}
    \setlength{\abovecaptionskip}{-20pt}
\end{figure}


\section*{About k-Nearest Neighbor Algorithm}

\lipsum[1-1]

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/knn.png}
    \caption*{Prediction accuracy of kNN Classifier \\
    as a function of k (Number of Neighbours)}
    \setlength{\belowcaptionskip}{-20pt}
    \setlength{\abovecaptionskip}{-20pt}
\end{figure}


%\lipsum[1-1]

\begin{table}[H]
    \centering
    \begin{tabular}{llllllllllll}
        Predicted & 0 & 1     & 2     & 3     & 4    & 5    & 6    & 7     & 8    & 9    & All \\
        Actual &      &       &       &       &      &      &      &       &      &      &        \\
        0      &  975 &     1 &     1 &     0 &    0 &    1 &    1 &     1 &    0 &    0 &    980 \\
        1      &    0 &  1131 &     1 &     0 &    0 &    0 &    3 &     0 &    0 &    0 &   1135 \\
        2      &    7 &     1 &  1003 &     0 &    1 &    0 &    3 &    11 &    6 &    0 &   1032 \\
        3      &    0 &     2 &     4 &   973 &    0 &   13 &    0 &     6 &   10 &    2 &   1010 \\
        4      &    0 &     0 &     0 &     0 &  960 &    0 &    4 &     2 &    0 &   16 &    982 \\
        5      &    3 &     2 &     1 &     9 &    1 &  868 &    5 &     1 &    1 &    1 &    892 \\
        6      &    4 &     4 &     0 &     0 &    3 &    0 &  947 &     0 &    0 &    0 &    958 \\
        7      &    1 &    20 &    10 &     0 &    2 &    0 &    0 &   985 &    0 &   10 &   1028 \\
        8      &    3 &     0 &     3 &    14 &    4 &    5 &    1 &     2 &  938 &    4 &    974 \\
        9      &    4 &     3 &     3 &    10 &   14 &    6 &    1 &     7 &    4 &  957 &   1009 \\
        All    &  997 &  1164 &  1026 &  1006 &  985 &  893 &  965 &  1015 &  959 &  990 &  10000 \\
    \end{tabular}
    \caption*{Confusion Matrix of kNN classifier with 6 neighbors\\
    Accuracy: 97.37\%}
\end{table}

%\cite{watson_2020s}

%\begin{lstlisting}[language=Python, caption=Caption for the snippet]
%# Code snippet
%print("I am a code snippet!")
%\end{lstlisting}

%\newpage

\section*{Results}

\lipsum[1-3]

\section*{Section Title}
\lipsum[1-2]

